{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ab41a0-c438-4f73-bb06-45a37aa4ccd3",
   "metadata": {},
   "source": [
    "## Pythonによる画像解析実例 #5: 出芽酵母位相差像の分節化と蛍光granuleの解析  \n",
    "\\#3で確立した画像解析を修正、より細かな細胞内顆粒（eg. Ade4-mNG顆粒）を検出可能にする。  \n",
    "具体的にはfociを検出する場合はz-stackをMax int. projectionした像をそのまま使用していたが、projection後にRolling ball background, rolling = 10でバックグラウンドを差し引いてから解析。  \n",
    "位相差像から細胞の輪郭を検出するプログラムに変更無し。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6cfebd9-ad73-4600-9578-6dfc05bd95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nd2\n",
    "import os\n",
    "import imageio\n",
    "from tifffile import tifffile as tiff\n",
    "import PySimpleGUI as sg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "import cv2\n",
    "from cv2_rolling_ball import subtract_background_rolling_ball\n",
    "\n",
    "from skimage.color import label2rgb\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import exposure\n",
    "from skimage.filters import threshold_li\n",
    "from skimage.measure import regionprops_table\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import binary_opening\n",
    "from skimage.morphology import binary_dilation\n",
    "from skimage.morphology import extrema\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.morphology import square\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage import restoration\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.util import img_as_uint\n",
    "from skimage.util import invert\n",
    "# from skimage.util import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0be6ab-99e8-413a-9539-e61299571f2b",
   "metadata": {},
   "source": [
    "位相差像のラベル化画像の作成までを関数化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a6d076-9849-480e-a279-9ea07fcea420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segm_phimg(img0, radius = 25, ratio = 0.1):\n",
    "\n",
    "    img1 = img0[1,:,:]\n",
    "    gblur = cv2.GaussianBlur(\n",
    "        img1,    # 入力画像\n",
    "        (0, 0), # カーネルのサイズを０にしてσの値からカーネルサイズを自動計算\n",
    "        1       # X方向のσの値, Y方向のσを指定しないとXと同じ値になる\n",
    "        )\n",
    "    background = restoration.rolling_ball(gblur, radius = radius, kernel=None,\n",
    "                                     nansafe=False, num_threads=None)\n",
    "    filtered = gblur - background\n",
    "    \n",
    "    thresh = threshold_li(filtered)\n",
    "    mask = np.where(filtered > thresh, 1, 0) # numpyによる2値化処理\n",
    "\n",
    "    arr = mask > 0\n",
    "    cleaned = remove_small_objects(arr, min_size=256)\n",
    "    cleaned = img_as_ubyte(cleaned)\n",
    "\n",
    "    erosion = ndimage.binary_erosion(cleaned, iterations= 2).astype(cleaned.dtype)\n",
    "\n",
    "    sk = skeletonize(erosion, method='lee')\n",
    "    sk_dil = ndimage.binary_dilation(sk, iterations= 1).astype(sk.dtype)\n",
    "    sk_close = ndimage.binary_closing(sk_dil, iterations=1).astype(sk_dil.dtype)\n",
    "\n",
    "    filled = ndimage.binary_fill_holes(sk_close).astype(\"uint8\")\n",
    "    diff = filled - sk_close\n",
    "    filled2= ndimage.binary_fill_holes(diff).astype(\"uint8\")\n",
    "    sure_bg = ndimage.binary_dilation(filled2, iterations= 1).astype(filled2.dtype)\n",
    "\n",
    "    dist_transform = cv2.distanceTransform(filled2, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, ratio*dist_transform.max(),255,0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    sure_bg = np.uint8(sure_bg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    # ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    ret, markers, stats, centroids = cv2.connectedComponentsWithStats(sure_fg)\n",
    "    markers = markers+1\n",
    "    markers[unknown == 1] = 0 # boolean indexing\n",
    "    \n",
    "    img1_1 = exposure.rescale_intensity(img1)  # 明るさを調整\n",
    "    img1_8b = img_as_ubyte(img1_1)\n",
    "    img1_8b_rgb = cv2.cvtColor(img1_8b, cv2.COLOR_GRAY2RGB)\n",
    "    markers = cv2.watershed(img1_8b_rgb, markers) # imgはRGBである必要がある\n",
    "    \n",
    "    #オーバーレイ画像の作成\n",
    "    img1 = exposure.rescale_intensity(img1)  # 明るさを調整\n",
    "    img1_2 = img_as_ubyte(img1)\n",
    "    img_rgb_segm = cv2.cvtColor(img1_2, cv2.COLOR_GRAY2RGB)\n",
    "    img_rgb_segm[markers == -1] = (255, 0, 0)\n",
    "    \n",
    "    # numbered = img_rgb_segm.copy()\n",
    "    # for i in range(1, len(stats)):\n",
    "    #     x, y, width, height, area = stats[i]  # このAreaは何を表している？\n",
    "    #     cv2.putText(numbered, f\"{i}\", (x, y-20), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    return markers, stats, centroids, img_rgb_segm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e824dde-3afe-47ba-a099-b8d62fef42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df内のmaximaのラベル画像と各領域の元画像から、overlay画像を作るための関数\n",
    "def make_overlay(df):\n",
    "    return label2rgb(df[\"label_h_maxima\"], df[\"image_intensity\"]*3, alpha=0.2, bg_label=0,\n",
    "                          bg_color=None, colors=[(1, 0, 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9417e0-38f3-49d2-a692-312addb44b59",
   "metadata": {},
   "source": [
    "df内で個々のmaximaを解析して、結果を新しい列に格納するための関数  \n",
    "fociを持たない細胞の場合は全ての値でNaNを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfc248d-cdf1-45ba-aae6-d52423d58e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_maxima(df):\n",
    "    if df[\"with_foci\"] == 1:\n",
    "        dic = regionprops_table(df[\"label_h_maxima\"], intensity_image = df[\"image_intensity\"], properties=[\"label\", \"area\", \"intensity_max\", \"intensity_mean\"])\n",
    "        foci_df = pd.DataFrame(dic)\n",
    "    else:\n",
    "        dic = {\"label\":np.nan, \"area\":np.nan, \"intensity_max\":np.nan, \"intensity_mean\":np.nan}\n",
    "        foci_df = pd.DataFrame(dic, index=[0])# indexを何か指定しないとエラー\n",
    "    foci_df[\"cell_label\"] = df.cell_label\n",
    "    foci_df[\"cell_area\"] = df.cell_area\n",
    "    foci_df[\"with_foci\"] = df.with_foci\n",
    "    \n",
    "    return foci_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b366f8-f6e7-4ccd-8ff1-cc152546d569",
   "metadata": {},
   "source": [
    "作成したラベル化画像を入力して、各領域（各細胞）の面積やfociの有無等についてまとめたデータフレームdfと個々のfociについて計測してまとめたデータフレームdf_fociを返す関数  \n",
    "\n",
    "引数として受け取った画像のバックグラウンドをskimageのrolling-ball methodで差し引くように変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc6e510-64fe-4854-a19d-26e9652ace92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_foci(markers, img0, prominence):\n",
    "    img1 = img0[0,:,:]\n",
    "    # background = restoration.rolling_ball(img1, radius = 10, kernel=None,\n",
    "    #                                  nansafe=False, num_threads=None)\n",
    "    # img2 = img1 - background\n",
    "    \n",
    "    # cv2のrolling-ballを使用する場合、入力画像のimgも変更される\n",
    "    img1_8b = img_as_ubyte(img1) #8bit画像に変換\n",
    "    radius = 10\n",
    "    img2_8b, background = subtract_background_rolling_ball(img1_8b, radius, light_background=False,\n",
    "                                     use_paraboloid=False, do_presmooth=False)\n",
    "    img2 = img_as_uint(img2_8b)\n",
    "    \n",
    "    img_properties = [\"label\", \"area\",\"image_intensity\"]\n",
    "    prop_dic = regionprops_table(markers, intensity_image=img2, properties=img_properties)\n",
    "    df = pd.DataFrame(prop_dic)\n",
    "    df = df.rename(columns = {\"label\": \"cell_label\"})\n",
    "    df = df.rename(columns = {\"area\": \"cell_area\"})\n",
    "    df = df.drop([0]) # バックグラウンドのデータを削除\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"cell_label\"] = df[\"cell_label\"] - 1 # 画像のラベル番号と合わせるため\n",
    "    \n",
    "    # ImageJ/FIJIマクロと同様の解析条件:\n",
    "    min_th = 400  # 解析対象のcell_areaの下限\n",
    "    max_th = 3000 # 解析対象のcell_areaの上限\n",
    "    \n",
    "    # 別法： 平均値とSDから上限と下限を決める\n",
    "    # cell_area_mean = df[\"cell_area\"].mean()\n",
    "    # cell_area_sdv = df[\"cell_area\"].std()\n",
    "    # min_th = cell_area_mean/3  # 解析対象のcell_areaの下限： 平均/3\n",
    "    # max_th = cell_area_mean + 3*cell_area_sdv # 解析対象のcell_areaの上限： 平均 + 3*SD\n",
    "    \n",
    "    # 条件に合致する行を抽出\n",
    "    labels_extracted = df[(df[\"cell_area\"] < max_th) & (min_th < df[\"cell_area\"])][\"cell_label\"]\n",
    "    df = df[(df[\"cell_area\"] < max_th) & (min_th < df[\"cell_area\"])]\n",
    "    \n",
    "    df[\"h_maxima\"] = df[\"image_intensity\"].map(lambda x: extrema.h_maxima(x, prominence, footprint=None))\n",
    "    df[\"num_maxima\"] = df[\"h_maxima\"].map(lambda x: x.sum()) # mapを使わないとエラー\n",
    "    df[\"with_foci\"] = df[\"num_maxima\"].map(lambda x: 0 if x == 0 else 1)\n",
    "    # さらに極大点のdilation、ラベリングまでdataframe内で行う\n",
    "    # df[\"h_maxima_dil\"]= df[\"h_maxima\"].map(lambda x: ndimage.binary_dilation(x, iterations= 1).astype(x.dtype))\n",
    "    df[\"h_maxima_dil\"]= df[\"h_maxima\"].map(lambda x: binary_dilation(x, footprint = square(2)).astype(x.dtype))\n",
    "    df[\"label_h_maxima\"] = df[\"h_maxima_dil\"].map(label)\n",
    "    df[\"overlay_h\"] = df.apply(make_overlay, axis=1) # 自作関数によるオーバーレイ画像の作成\n",
    "    df[\"foci_df\"] = df.apply(detect_maxima, axis=1)#自作関数による各maximaの解析\n",
    "    \n",
    "    total_cells = len(df)\n",
    "    cells_wfoci = len(df[df[\"with_foci\"] == 1])\n",
    "    cells_wofoci = total_cells - cells_wfoci\n",
    "    pct_fcells = cells_wfoci/total_cells*100\n",
    "    # データフレームに追加しやすいよう辞書形式でまとめておく\n",
    "    res_dic = {\"total cells\": total_cells, \"cells_with_foci\": cells_wfoci, \"pct_foci_cells\":pct_fcells, \"prominence\":prominence}\n",
    "\n",
    "    foci_df = pd.concat(list(df[\"foci_df\"]))\n",
    "    foci_df = foci_df.rename(columns = {\"label\": \"foci_label\"})\n",
    "    foci_df = foci_df.iloc[:, [4,5,6,0,1,2,3]]\n",
    "    return df, foci_df, res_dic, labels_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aedf244-8b94-44c6-be17-645eb6fe2af5",
   "metadata": {},
   "source": [
    "cell_areaの条件で抽出したcellにのみ番号を振った画像を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55bf77c-5734-4615-9c34-b11e6f9b43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbering_extracted_cells(img_rgb_segm, stats, labels_extracted):\n",
    "    numbered = img_rgb_segm.copy()\n",
    "    for i in range(1, len(stats)):\n",
    "        if i in np.asarray(labels_extracted):\n",
    "            x, y, width, height, area = stats[i]  # このAreaは何を表している？\n",
    "            cv2.putText(numbered, f\"{i}\", (x, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    return numbered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5ac42-965b-4699-9386-5115891813b5",
   "metadata": {},
   "source": [
    "あるフォルダに存在するnd2ファイルを順番に読み込んで、fociを持つ細胞の割合およびfociの輝度を計測、各ファイルの結果をまとめたデータフレームを作成  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "457f27f0-1310-4d16-a9cd-12517ce57760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "8min 46s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "\n",
    "prominence = 750\n",
    "# folderS = \"/Users/masak_takaine/210625_ade4GFP/nd\"\n",
    "folderS = \"/Users/masak_takaine/221025_Ade4-mNG_HD_2ugml_digit/nd/test\"\n",
    "# folderD = \"/Users/masak_takaine/210625_ade4GFP/nd_test_results\"\n",
    "folderD = \"/Users/masak_takaine/221025_Ade4-mNG_HD_2ugml_digit/python\"\n",
    "date = \"test\"\n",
    "file_list = glob.glob(folderS + \"/*\") #フォルダ内の全てのfile/folderのリストを取得して、ソートしておく\n",
    "file_list.sort(reverse=True) \n",
    "\n",
    "# 各ファイルの解析結果を格納するリスト\n",
    "fname_list = []\n",
    "vsize_list =[]\n",
    "res_df_list = []\n",
    "foci_df_list = []\n",
    "segm_img_list = []\n",
    "\n",
    "csv_folder = os.path.join(folderD, \"csv\")\n",
    "if not os.path.exists(csv_folder):  #dirが存在しなければ作成する\n",
    "    os.mkdir(csv_folder)  \n",
    "\n",
    "segm_img_folder = os.path.join(folderD, \"segmented_images\")    \n",
    "if not os.path.exists(segm_img_folder):  \n",
    "    os.mkdir(segm_img_folder) \n",
    "\n",
    "for path in file_list:\n",
    "    filename = os.path.basename(path).split(\".\")[0]\n",
    "    nd2_arr =nd2.imread(path) # 画像をndarrayとして読み込み\n",
    "    with nd2.ND2File(path) as f: # with構文でファイルを開くと様々なメタデータが抽出できる\n",
    "        vsize = f.voxel_size() # \n",
    "    img0 = np.max(nd2_arr, axis = 0) # z-planeを表すaxis = 0の最大値を計算\n",
    "    markers, stats, centroids, img_rgb_segm = segm_phimg(img0)\n",
    "    df, foci_df, res_dic, labels_extracted = analyze_foci(markers, img0, prominence)\n",
    "    numbered = numbering_extracted_cells(img_rgb_segm, stats, labels_extracted)\n",
    "    \n",
    "    fname_list.append(filename)\n",
    "    vsize_list.append(vsize)\n",
    "    res_dic[\"filename\"] = filename\n",
    "    res_dic[\"Date\"] = date\n",
    "    res_df = pd.DataFrame(res_dic, index=[0])# indexを何か指定しないとエラー\n",
    "    res_df = res_df.iloc[:, [5,4,0,1,2,3]] # 並べ替え\n",
    "    res_df_list += [res_df] # リストは+=で簡単に連結できる\n",
    "    \n",
    "    foci_df[\"filename\"] = filename\n",
    "    foci_df[\"Date\"] = date\n",
    "    foci_df = foci_df.iloc[:, [7,6,0,1,2,3,4,5]]\n",
    "    foci_df_list += [foci_df]\n",
    "    \n",
    "    segm_img_list += [numbered]\n",
    "\n",
    "df_concat = pd.concat(res_df_list)\n",
    "df_concat = df_concat.reset_index(drop=True) # indexを振り直す\n",
    "stats_csv_savepath = os.path.join(csv_folder, date + \"_stats.csv\")\n",
    "df_concat.to_csv(stats_csv_savepath)\n",
    "\n",
    "foci_df_concat = pd.concat(foci_df_list)\n",
    "foci_df_concat = foci_df_concat.reset_index(drop=True)\n",
    "fdata_csv_savepath = os.path.join(csv_folder, date + \"_focidata.csv\")\n",
    "foci_df_concat.to_csv(fdata_csv_savepath)\n",
    "\n",
    "for filename, vsize, numbered in zip(fname_list, vsize_list, segm_img_list):\n",
    "    segm_img_savepath = os.path.join(segm_img_folder, filename + \"_segmented.tif\")\n",
    "    tiff.imwrite(segm_img_savepath, numbered, imagej = True, resolution = (1/vsize.x, 1/vsize.y), metadata={'unit': 'um'})\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf0f66-5ccc-43e8-a3a4-57e71b41e034",
   "metadata": {},
   "source": [
    "35個のnd2ファイルの解析と測定結果の保存にかかる時間を計測:  \n",
    "folderS = \"/Users/masak_takaine/210625_ade4GFP/nd\"  \n",
    "folderD = \"/Users/masak_takaine/210625_ade4GFP/nd_test_results\"  \n",
    "1min 1s ± 238 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)  \n",
    "同じファイルをFIJIのJythonスクリプトで処理すると、約20分かかった"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee38cf6-1032-4f5b-94b6-f38fad3ba632",
   "metadata": {},
   "source": [
    "さらに読み込むファイルの入ったフォルダ（source folder）と保存先のフォルダ（destination folder）をGUIで指定できるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60faa9f-563d-4ff1-b2fc-281d9b4da372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "layout = [\n",
    "    [sg.Text(\"Date of experiments:\"), sg.InputText(key=\"date\",default_text = \"test\")],\n",
    "   [sg.Text(\"Source folder:\"), sg.InputText(key=\"folderS\")],[sg.FolderBrowse(target=\"folderS\", initial_folder= os.getcwd())],\n",
    "    [sg.Text(\"Destination folder:\"), sg.InputText(key=\"folderD\")],[sg.FolderBrowse(target=\"folderD\", initial_folder= os.getcwd())],\n",
    "    [sg.Text(\"Prominence:\"), sg.InputText(key=\"prom\",default_text = \"2000\")],\n",
    "          [sg.Submit(), sg.Cancel()],\n",
    "]\n",
    "\n",
    "window = sg.Window(\"Choose folders\", layout)\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    if event in (sg.WIN_CLOSED, 'Cancel'):\n",
    "        break\n",
    "    # elif event == 'Submit':\n",
    "    else:\n",
    "        date = values[\"date\"]\n",
    "        folderS = values[\"folderS\"]\n",
    "        folderD = values[\"folderD\"]\n",
    "        prominence = int(values[\"prom\"])\n",
    "        file_list = glob.glob(folderS + \"/*\") #フォルダ内の全てのfile/folderのリストを取得して、ソートしておく\n",
    "        file_list.sort(reverse=True) \n",
    "\n",
    "        # 各ファイルの解析結果を格納するリスト\n",
    "        fname_list = []\n",
    "        vsize_list =[]\n",
    "        res_df_list = []\n",
    "        foci_df_list = []\n",
    "        segm_img_list = []\n",
    "\n",
    "        csv_folder = os.path.join(folderD, \"csv\")\n",
    "        if not os.path.exists(csv_folder):  #dirが存在しなければ作成する\n",
    "            os.mkdir(csv_folder)  \n",
    "\n",
    "        segm_img_folder = os.path.join(folderD, \"segmented_images\")    \n",
    "        if not os.path.exists(segm_img_folder):  \n",
    "            os.mkdir(segm_img_folder) \n",
    "\n",
    "        for path in file_list:\n",
    "            filename = os.path.basename(path).split(\".\")[0]\n",
    "            nd2_arr =nd2.imread(path) # 画像をndarrayとして読み込み\n",
    "            with nd2.ND2File(path) as f: # with構文でファイルを開くと様々なメタデータが抽出できる\n",
    "                vsize = f.voxel_size() # \n",
    "            img0 = np.max(nd2_arr, axis = 0) # Max intensity projection, z-planeを表すaxis = 0の最大値を計算\n",
    "            markers, stats, centroids, img_rgb_segm = segm_phimg(img0)\n",
    "            df, foci_df, res_dic, labels_extracted = analyze_foci(markers, img0, prominence)\n",
    "            numbered = numbering_extracted_cells(img_rgb_segm, stats, labels_extracted)\n",
    "\n",
    "            fname_list.append(filename)\n",
    "            vsize_list.append(vsize)\n",
    "            res_dic[\"filename\"] = filename\n",
    "            res_dic[\"Date\"] = date\n",
    "            res_df = pd.DataFrame(res_dic, index=[0])# indexを何か指定しないとエラー\n",
    "            res_df = res_df.iloc[:, [5,4,0,1,2,3]] # 並べ替え\n",
    "            res_df_list += [res_df] # リストは+=で簡単に連結できる\n",
    "\n",
    "            foci_df[\"filename\"] = filename\n",
    "            foci_df[\"Date\"] = date\n",
    "            foci_df = foci_df.iloc[:, [7,6,0,1,2,3,4,5]]\n",
    "            foci_df_list += [foci_df]\n",
    "\n",
    "            segm_img_list += [numbered]\n",
    "\n",
    "        df_concat = pd.concat(res_df_list)\n",
    "        df_concat = df_concat.reset_index(drop=True) # indexを振り直す\n",
    "        stats_csv_savepath = os.path.join(csv_folder, date + \"_stats.csv\")\n",
    "        df_concat.to_csv(stats_csv_savepath)\n",
    "\n",
    "        foci_df_concat = pd.concat(foci_df_list)\n",
    "        foci_df_concat = foci_df_concat.reset_index(drop=True)\n",
    "        fdata_csv_savepath = os.path.join(csv_folder, date + \"_focidata.csv\")\n",
    "        foci_df_concat.to_csv(fdata_csv_savepath)\n",
    "\n",
    "        for filename, vsize, numbered in zip(fname_list, vsize_list, segm_img_list):\n",
    "            segm_img_savepath = os.path.join(segm_img_folder, filename + \"_segmented.tif\")\n",
    "            tiff.imwrite(segm_img_savepath, numbered, imagej = True, resolution = (1/vsize.x, 1/vsize.y), metadata={'unit': 'um'})\n",
    "        print(\"Done.\")\n",
    "        break\n",
    "        \n",
    "window.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e92ccd-f0a6-4951-94fd-a091157e7720",
   "metadata": {},
   "source": [
    "さらに各チャンネルの画像のMIPをまとめた、ImageJ hyperstackファイルを作成する機能を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935068bb-fb1a-42f2-abe1-eb10d8ff8f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = [\n",
    "    [sg.Text(\"Date of experiments:\"), sg.InputText(key=\"date\",default_text = \"test\")],\n",
    "   [sg.Text(\"Source folder:\"), sg.InputText(key=\"folderS\")],[sg.FolderBrowse(target=\"folderS\", initial_folder= os.getcwd())],\n",
    "    [sg.Text(\"Destination folder:\"), sg.InputText(key=\"folderD\")],[sg.FolderBrowse(target=\"folderD\", initial_folder= os.getcwd())],\n",
    "    [sg.Text(\"Prominence:\"), sg.InputText(key=\"prom\",default_text = \"2000\")],\n",
    "    # [sg.Text(\"Prominence:\"), sg.InputText(key=\"prom\")],\n",
    "          [sg.Submit(), sg.Cancel()],\n",
    "]\n",
    "\n",
    "window = sg.Window(\"Choose folders\", layout)\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    if event in (sg.WIN_CLOSED, 'Cancel'):\n",
    "        break\n",
    "    # elif event == 'Submit':\n",
    "    else:\n",
    "        date = values[\"date\"]\n",
    "        folderS = values[\"folderS\"]\n",
    "        folderD = values[\"folderD\"]\n",
    "        prominence = int(values[\"prom\"])\n",
    "        file_list = glob.glob(folderS + \"/*\") #フォルダ内の全てのfile/folderのリストを取得して、ソートしておく\n",
    "        file_list.sort(reverse=True) \n",
    "\n",
    "        # 各ファイルの解析結果を格納するリスト\n",
    "        fname_list = []\n",
    "        vsize_list =[]\n",
    "        res_df_list = []\n",
    "        foci_df_list = []\n",
    "        segm_img_list = []\n",
    "        \n",
    "        ch0_list = []\n",
    "        ch1_list = []\n",
    "\n",
    "        csv_folder = os.path.join(folderD, \"csv\")\n",
    "        if not os.path.exists(csv_folder):  #dirが存在しなければ作成する\n",
    "            os.mkdir(csv_folder)  \n",
    "\n",
    "        segm_img_folder = os.path.join(folderD, \"segmented_images\")    \n",
    "        if not os.path.exists(segm_img_folder):  \n",
    "            os.mkdir(segm_img_folder) \n",
    "\n",
    "        for path in file_list:\n",
    "            filename = os.path.basename(path).split(\".\")[0]\n",
    "            nd2_arr =nd2.imread(path) # 画像をndarrayとして読み込み\n",
    "            with nd2.ND2File(path) as f: # with構文でファイルを開くと様々なメタデータが抽出できる\n",
    "                vsize = f.voxel_size() # \n",
    "            img0 = np.max(nd2_arr, axis = 0) # Max intensity projection, z-planeを表すaxis = 0の最大値を計算\n",
    "            markers, stats, centroids, img_rgb_segm = segm_phimg(img0)\n",
    "            df, foci_df, res_dic, labels_extracted = analyze_foci(markers, img0, prominence)\n",
    "            numbered = numbering_extracted_cells(img_rgb_segm, stats, labels_extracted)\n",
    "\n",
    "            fname_list.append(filename)\n",
    "            vsize_list.append(vsize)\n",
    "            res_dic[\"filename\"] = filename\n",
    "            res_dic[\"Date\"] = date\n",
    "            res_df = pd.DataFrame(res_dic, index=[0])# indexを何か指定しないとエラー\n",
    "            res_df = res_df.iloc[:, [5,4,0,1,2,3]] # 並べ替え\n",
    "            res_df_list += [res_df] # リストは+=で簡単に連結できる\n",
    "\n",
    "            foci_df[\"filename\"] = filename\n",
    "            foci_df[\"Date\"] = date\n",
    "            foci_df = foci_df.iloc[:, [7,6,0,1,2,3,4,5]]\n",
    "            foci_df_list += [foci_df]\n",
    "\n",
    "            segm_img_list += [numbered]\n",
    "            \n",
    "            # hyperstack作成のため、各チャンネル画像をリストに格納\n",
    "            h, w = img0.shape[1], img0.shape[2]\n",
    "            img0_ch0 = img0[0,:,:].reshape(1, h, w) # (frame, y, x)に次元変更\n",
    "            img0_ch1 = img0[1,:,:].reshape(1, h, w)\n",
    "            ch0_list.append(img0_ch0)\n",
    "            ch1_list.append(img0_ch1)\n",
    "\n",
    "        df_concat = pd.concat(res_df_list)\n",
    "        df_concat = df_concat.reset_index(drop=True) # indexを振り直す\n",
    "        stats_csv_savepath = os.path.join(csv_folder, date + \"_stats.csv\")\n",
    "        df_concat.to_csv(stats_csv_savepath)\n",
    "\n",
    "        foci_df_concat = pd.concat(foci_df_list)\n",
    "        foci_df_concat = foci_df_concat.reset_index(drop=True)\n",
    "        fdata_csv_savepath = os.path.join(csv_folder, date + \"_focidata.csv\")\n",
    "        foci_df_concat.to_csv(fdata_csv_savepath)\n",
    "\n",
    "        for filename, vsize, numbered in zip(fname_list, vsize_list, segm_img_list):\n",
    "            segm_img_savepath = os.path.join(segm_img_folder, filename + \"_segmented.tif\")\n",
    "            tiff.imwrite(segm_img_savepath, numbered, imagej = True, resolution = (1/vsize.x, 1/vsize.y), metadata={'unit': 'um'})\n",
    "            \n",
    "        # vstackでリスト内の画像を1つ目の軸にまとめる\n",
    "        ch0_stack = np.vstack(ch0_list)\n",
    "        ch1_stack = np.vstack(ch1_list)\n",
    "        # 観察中に解像度が変更されることは無いので、最初のvsizeだけ使用\n",
    "        vsize0 = vsize_list[0]\n",
    "        reso = (1/vsize0.x, 1/vsize0.y)\n",
    "        tiff.imwrite(os.path.join(folderD,'ch0_stack.tif'),ch0_stack,imagej=True,resolution= reso,\n",
    "             metadata={\n",
    "                # 'spacing': 3.947368,\n",
    "                 'unit': 'um',\n",
    "                 # 'finterval': 1/10,\n",
    "                 # 'fps': 10.0,\n",
    "               'axes': 'TYX',\n",
    "                 'Labels': fname_list,\n",
    "                     })\n",
    "        tiff.imwrite(os.path.join(folderD,'ch1_stack.tif'),ch1_stack,imagej=True,resolution= reso,\n",
    "             metadata={\n",
    "                # 'spacing': 3.947368,\n",
    "                 'unit': 'um',\n",
    "                 # 'finterval': 1/10,\n",
    "                 # 'fps': 10.0,\n",
    "               'axes': 'TYX',\n",
    "                 'Labels': fname_list,\n",
    "                     })\n",
    "        \n",
    "        print(\"Done.\")\n",
    "        break\n",
    "        \n",
    "window.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3996190-2def-45fe-97e6-18ae8ab48b1f",
   "metadata": {},
   "source": [
    "### 考察  \n",
    "* 今までFIJIのマクロで行っていた処理をほぼ完全にPythonで再現することに成功した。  \n",
    "* 解析対象の細胞の大きさはマクロと同じく400-3000にしているが、解析結果（fociを持つ細胞の割合）はFIJIマクロとPythonで若干異なる。  \n",
    "これは細胞を検出するための手順の違いによるものだと考えられる。\n",
    "* Pythonの方がfociを持つ細胞の割合が10%程度高く見積もられる。\n",
    "* また細胞のラベルも大きくなる傾向があるので、300-2000くらいが大きさの範囲として適切かもしれない。\n",
    "* Pythonでは35個のファイルを処理するのに1分程度しかかからない。同様の処理でFIJIでは20−30分かかっていたので、少なくとも20倍の高速化を実現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce89910-a0f1-4e5f-8f3d-d94c337c0dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
